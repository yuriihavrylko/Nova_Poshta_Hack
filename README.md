# Nova Poshta RAG Project

The Nova Poshta RAG project was developed as part of an innovation hackathon organized by [Nova Poshta](https://techukraine.org/2023/08/15/innovation-hackathon-by-nova-poshta/). The goal of this project was to create a robust solution enhancing the Nova Poshta customer experience through advanced tech solutions.

## Demo
[![](https://i.imgur.com/Kkhicev.png)](https://youtu.be/k9l0icVgh2Q)

## Quick Start

To get started with the project, ensure you have Docker installed on your system. Then, run the following command in the project directory to build and start the container:

```
docker compose up
```

After the containers have been successfully started, you can access the project's features through the designated ports communicated in the terminal.

## Features

This project encapsulates a set of advanced features aimed at streamlining customer experiences and operational efficiencies, including:

- **Streamlit Chat View**: An interactive chat interface built with Streamlit, allowing users to engage in real-time conversations.
- **Vector DB with Nova Poshta Data**: Utilizes a vector database to efficiently manage and query large sets of Nova Poshta data, enhancing search capabilities and response times.
- **Speech to Text**: Innovative speech recognition features that convert spoken language into written text, facilitating easier communication and documentation.
- **Text to Speech**: Converts written text into spoken language, making the app more accessible and enhancing user interactions, particularly for users with visual impairments or those who prefer audio feedback.
- **Ukrainian Language Support**: Fully supports the Ukrainian language for all features, ensuring that local users can interact with the system in their native language, enhancing usability and user satisfaction.

## Used Technologies and Workflow

### Vector - ChromaDB
ChromaDB is the vector storage system that we utilize in this project. It brings efficiency and performance in managing and processing our vector data.

### Framework - LangChain
LangChain is the backbone of our framework, empowering us to build the project structure in an organized and flexible manner. It also equips us with functionalities to incorporate various features easily.

### LLM Backend - GPT-3.5-turbo
Our language model backend supports the use of GPT-3.5-turbo. Its advanced machine learning capabilities create a powerful AI system capable of understanding and interacting with the user at an elevated level.

### Speech-To-Text Technologies
For the conversion of speech into text, we've integrated technologies suitable for different languages for optimal results.

- **Ukrainian (uk): SqueezeFormer**
SqueezeFormer is used for Ukrainian speech, which provides accurate transcription even in noisy environments and across various speakers.

- **English (en): FastConformer**
FastConformer, employed for English speech processing, assures a fast and precise automatic conversion of spoken words to written format. 

### Text-To-Speech Technologies
For translating text to speech, we use the following technology depending on the language context:

- **Ukrainian & English (uk, en): Balacoon**
Balacoon allows seamless transformation of text into natural-sounding speech in both Ukrainian and English languages. It serves to make our system increasingly interactable and user-friendly. 

### Workflow

Our workflow is designed to deliver a seamless user experience and is structured as follows:

- **Document Indexing**: We begin by indexing documents from the Nova Poshta website to ChromaDB. This step allows us to efficiently store, manage, and retrieve the required information.

- **User Input**: The user has the option to either write text or use voice input. This flexibility enables a more convenient and personalized interaction.

- **Semantic Search**: The system conducts a semantic search based on the user's input. By understanding the context beyond just keywords, it aims to fetch the most accurate results.

- **Preparing and Waiting for LLM Prompt Output**: Then, the system prepares the LLM prompt and waits for the output. Using the power of GPT-3.5-turbo, the LLM backend generates a context-aware response.

- **Returning Result to Chat**: The response generated by the system is then returned to the chat. This ensures direct communication and rapid feedback for the user.

- **Text-to-Speech Option**: For users who prefer an audible response, we also provide a text-to-speech feature, with high-quality voice synthesis powered by Balacoon.

This streamlined workflow ensures rapid processing of user input, delivering accurate and context-aware results, thus enhancing the user's overall experience with the system.
